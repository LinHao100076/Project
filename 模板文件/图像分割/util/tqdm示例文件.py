#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
tqdmè¿›åº¦æ¡åº“å®Œæ•´æ¼”ç¤ºé¡¹ç›®
åŸºäºåšå®¢ï¼šhttps://blog.csdn.net/AI_dataloads/article/details/134169038

æœ¬é¡¹ç›®æ¼”ç¤ºtqdmçš„å„ç§ç”¨æ³•ï¼š
1. åŸºç¡€è¿›åº¦æ¡ä½¿ç”¨
2. è¿›åº¦æ¡æè¿°è®¾ç½®
3. writeæ–¹æ³•ä½¿ç”¨
4. æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨
"""

import time
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from tqdm import tqdm, trange
import os


def demo_basic_usage():
    """æ¼”ç¤ºåŸºç¡€ç”¨æ³•"""
    print("=" * 50)
    print("1. åŸºç¡€è¿›åº¦æ¡æ¼”ç¤º")
    print("=" * 50)

    print("\n1.1 ä¼ å…¥å¯è¿­ä»£å¯¹è±¡:")
    for i in tqdm(range(100), desc="åŸºç¡€è¿›åº¦æ¡"):
        time.sleep(0.02)  # å‡å°‘ç­‰å¾…æ—¶é—´ä»¥ä¾¿æ¼”ç¤º

    print("\n1.2 ä½¿ç”¨trange:")
    for i in trange(100, desc="trangeæ¼”ç¤º"):
        time.sleep(0.02)


def demo_description():
    """æ¼”ç¤ºè¿›åº¦æ¡æè¿°è®¾ç½®"""
    print("\n" + "=" * 50)
    print("2. è¿›åº¦æ¡æè¿°è®¾ç½®æ¼”ç¤º")
    print("=" * 50)

    items = ["æ•°æ®é¢„å¤„ç†", "æ¨¡å‹è®­ç»ƒ", "æ¨¡å‹éªŒè¯", "ç»“æœä¿å­˜"]
    pbar = tqdm(items)
    for item in pbar:
        pbar.set_description(f"æ­£åœ¨å¤„ç†: {item}")
        time.sleep(1)


def demo_write_method():
    """æ¼”ç¤ºtqdmçš„writeæ–¹æ³•"""
    print("\n" + "=" * 50)
    print("3. tqdm writeæ–¹æ³•æ¼”ç¤º")
    print("=" * 50)

    bar = trange(20, desc="ä»»åŠ¡å¤„ç†")
    for i in bar:
        time.sleep(0.1)
        if not (i % 5):
            tqdm.write(f"âœ“ å®Œæˆä»»åŠ¡ {i}")


class SimpleNeuralNetwork(nn.Module):
    """ç®€åŒ–çš„ç¥ç»ç½‘ç»œæ¨¡å‹"""

    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.hidden1 = nn.Linear(28 * 28, 128)
        self.hidden2 = nn.Linear(128, 64)
        self.hidden3 = nn.Linear(64, 32)
        self.out = nn.Linear(32, 10)

    def forward(self, x):
        x = self.flatten(x)
        x = torch.relu(self.hidden1(x))
        x = torch.sigmoid(self.hidden2(x))
        x = torch.relu(self.hidden3(x))
        x = self.out(x)
        return x


def demo_deep_learning():
    """æ¼”ç¤ºåœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨"""
    print("\n" + "=" * 50)
    print("4. æ·±åº¦å­¦ä¹ ä¸­çš„tqdmåº”ç”¨æ¼”ç¤º")
    print("=" * 50)

    # æ£€æŸ¥è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # åˆ›å»ºç®€åŒ–çš„æ•°æ®é›†ï¼ˆé¿å…ä¸‹è½½å¤§æ–‡ä»¶ï¼‰
    print("\n4.1 åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†...")
    # åˆ›å»ºæ¨¡æ‹Ÿçš„MNISTæ•°æ®
    train_data = torch.randn(1000, 1, 28, 28)  # 1000ä¸ªæ ·æœ¬
    train_labels = torch.randint(0, 10, (1000,))  # å¯¹åº”æ ‡ç­¾

    test_data = torch.randn(200, 1, 28, 28)  # 200ä¸ªæµ‹è¯•æ ·æœ¬
    test_labels = torch.randint(0, 10, (200,))

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = torch.utils.data.TensorDataset(train_data, train_labels)
    test_dataset = torch.utils.data.TensorDataset(test_data, test_labels)

    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")

    # åˆ›å»ºæ¨¡å‹
    print("\n4.2 åˆ›å»ºç¥ç»ç½‘ç»œæ¨¡å‹...")
    model = SimpleNeuralNetwork().to(device)
    loss_fn = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # è®­ç»ƒå‡½æ•°
    def train_epoch(dataloader, model, loss_fn, optimizer):
        model.train()
        total_loss = 0
        correct = 0
        total = 0

        # ä½¿ç”¨tqdmæ˜¾ç¤ºè®­ç»ƒè¿›åº¦
        pbar = tqdm(dataloader, desc="è®­ç»ƒä¸­")
        for batch_idx, (data, targets) in enumerate(pbar):
            data, targets = data.to(device), targets.to(device)

            # å‰å‘ä¼ æ’­
            outputs = model(data)
            loss = loss_fn(outputs, targets)

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

            # æ›´æ–°è¿›åº¦æ¡æè¿°
            accuracy = 100. * correct / total
            avg_loss = total_loss / (batch_idx + 1)
            pbar.set_postfix({
                'Loss': f'{avg_loss:.4f}',
                'Acc': f'{accuracy:.2f}%'
            })

        return total_loss / len(dataloader), 100. * correct / total

    # æµ‹è¯•å‡½æ•°
    def test_epoch(dataloader, model, loss_fn):
        model.eval()
        test_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            pbar = tqdm(dataloader, desc="æµ‹è¯•ä¸­")
            for data, targets in pbar:
                data, targets = data.to(device), targets.to(device)
                outputs = model(data)
                test_loss += loss_fn(outputs, targets).item()

                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()

                # æ›´æ–°è¿›åº¦æ¡
                accuracy = 100. * correct / total
                pbar.set_postfix({'Acc': f'{accuracy:.2f}%'})

        return test_loss / len(dataloader), 100. * correct / total

    # å¼€å§‹è®­ç»ƒ
    print("\n4.3 å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    epochs = 3

    for epoch in range(epochs):
        print(f"\nEpoch {epoch + 1}/{epochs}")
        print("-" * 30)

        # è®­ç»ƒ
        train_loss, train_acc = train_epoch(train_dataloader, model, loss_fn, optimizer)

        # æµ‹è¯•
        test_loss, test_acc = test_epoch(test_dataloader, model, loss_fn)

        # è¾“å‡ºç»“æœ
        tqdm.write(f"Epoch {epoch + 1} ç»“æœ:")
        tqdm.write(f"  è®­ç»ƒ - Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%")
        tqdm.write(f"  æµ‹è¯• - Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%")


def demo_advanced_features():
    """æ¼”ç¤ºtqdmçš„é«˜çº§åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("5. tqdmé«˜çº§åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)

    print("\n5.1 åµŒå¥—è¿›åº¦æ¡:")
    for i in trange(3, desc="å¤–å±‚å¾ªç¯"):
        for j in trange(50, desc=f"å†…å±‚å¾ªç¯ {i + 1}", leave=False):
            time.sleep(0.01)

    print("\n5.2 æ‰‹åŠ¨æ›´æ–°è¿›åº¦æ¡:")
    pbar = tqdm(total=100, desc="æ‰‹åŠ¨æ›´æ–°")
    for i in range(10):
        # æ¨¡æ‹Ÿä¸è§„åˆ™çš„è¿›åº¦æ›´æ–°
        progress = (i + 1) * 10
        pbar.update(10)
        pbar.set_postfix({"æ­¥éª¤": f"{i + 1}/10"})
        time.sleep(0.2)
    pbar.close()

    print("\n5.3 æ–‡ä»¶å¤„ç†è¿›åº¦æ¡:")
    # æ¨¡æ‹Ÿæ–‡ä»¶å¤„ç†
    files = [f"file_{i}.txt" for i in range(20)]
    for filename in tqdm(files, desc="å¤„ç†æ–‡ä»¶"):
        # æ¨¡æ‹Ÿæ–‡ä»¶å¤„ç†æ—¶é—´
        time.sleep(0.1)
        if filename.endswith("5.txt") or filename.endswith("15.txt"):
            tqdm.write(f"âœ“ ç‰¹æ®Šå¤„ç†å®Œæˆ: {filename}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ tqdmè¿›åº¦æ¡åº“å®Œæ•´æ¼”ç¤º")
    print("åŸºäºåšå®¢: https://blog.csdn.net/AI_dataloads/article/details/134169038")
    print("=" * 60)

    try:
        # åŸºç¡€ç”¨æ³•æ¼”ç¤º
        demo_basic_usage()

        # æè¿°è®¾ç½®æ¼”ç¤º
        demo_description()

        # writeæ–¹æ³•æ¼”ç¤º
        demo_write_method()

        # æ·±åº¦å­¦ä¹ åº”ç”¨æ¼”ç¤º
        demo_deep_learning()

        # é«˜çº§åŠŸèƒ½æ¼”ç¤º
        demo_advanced_features()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 60)

    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


if __name__ == "__main__":
    main()